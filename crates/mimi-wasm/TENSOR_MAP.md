# Mimi Safetensors Weight Map

Actual tensor names and shapes from `kyutai/mimi` safetensors file (`models/mimi.safetensors`).

Generated by inspecting the file with `safetensors.safe_open()`.

## Encoder (SEANet)

Architecture: init_conv → 4x(ResidualBlock → ELU → Downsample) → ELU → final_conv

ResidualBlock = ELU → Conv1 → ELU → Conv2, with identity skip (no shortcut conv).

| Tensor | Shape | Description |
|--------|-------|-------------|
| `encoder.layers.0.conv.weight` | [64, 1, 7] | Init conv |
| `encoder.layers.0.conv.bias` | [64] | Init conv bias |
| `encoder.layers.1.block.1.conv.weight` | [32, 64, 3] | ResBlock 1 conv1 |
| `encoder.layers.1.block.1.conv.bias` | [32] | |
| `encoder.layers.1.block.3.conv.weight` | [64, 32, 1] | ResBlock 1 conv2 |
| `encoder.layers.1.block.3.conv.bias` | [64] | |
| `encoder.layers.3.conv.weight` | [128, 64, 8] | Downsample 1 (stride=4) |
| `encoder.layers.3.conv.bias` | [128] | |
| `encoder.layers.4.block.1.conv.weight` | [64, 128, 3] | ResBlock 2 conv1 |
| `encoder.layers.4.block.1.conv.bias` | [64] | |
| `encoder.layers.4.block.3.conv.weight` | [128, 64, 1] | ResBlock 2 conv2 |
| `encoder.layers.4.block.3.conv.bias` | [128] | |
| `encoder.layers.6.conv.weight` | [256, 128, 10] | Downsample 2 (stride=5) |
| `encoder.layers.6.conv.bias` | [256] | |
| `encoder.layers.7.block.1.conv.weight` | [128, 256, 3] | ResBlock 3 conv1 |
| `encoder.layers.7.block.1.conv.bias` | [128] | |
| `encoder.layers.7.block.3.conv.weight` | [256, 128, 1] | ResBlock 3 conv2 |
| `encoder.layers.7.block.3.conv.bias` | [256] | |
| `encoder.layers.9.conv.weight` | [512, 256, 12] | Downsample 3 (stride=6) |
| `encoder.layers.9.conv.bias` | [512] | |
| `encoder.layers.10.block.1.conv.weight` | [256, 512, 3] | ResBlock 4 conv1 |
| `encoder.layers.10.block.1.conv.bias` | [256] | |
| `encoder.layers.10.block.3.conv.weight` | [512, 256, 1] | ResBlock 4 conv2 |
| `encoder.layers.10.block.3.conv.bias` | [512] | |
| `encoder.layers.12.conv.weight` | [1024, 512, 16] | Downsample 4 (stride=8) |
| `encoder.layers.12.conv.bias` | [1024] | |
| `encoder.layers.14.conv.weight` | [512, 1024, 3] | Final conv |
| `encoder.layers.14.conv.bias` | [512] | |

Channel progression: 1 → 64 → 128 → 256 → 512 → 1024 → 512
Downsample ratios: [4, 5, 6, 8] (total 960x)

## Encoder Transformer (8 layers, 8 heads, d_model=512)

For each layer `i` in 0..8:

| Tensor | Shape |
|--------|-------|
| `encoder_transformer.layers.{i}.self_attn.q_proj.weight` | [512, 512] |
| `encoder_transformer.layers.{i}.self_attn.k_proj.weight` | [512, 512] |
| `encoder_transformer.layers.{i}.self_attn.v_proj.weight` | [512, 512] |
| `encoder_transformer.layers.{i}.self_attn.o_proj.weight` | [512, 512] |
| `encoder_transformer.layers.{i}.input_layernorm.weight` | [512] |
| `encoder_transformer.layers.{i}.input_layernorm.bias` | [512] |
| `encoder_transformer.layers.{i}.post_attention_layernorm.weight` | [512] |
| `encoder_transformer.layers.{i}.post_attention_layernorm.bias` | [512] |
| `encoder_transformer.layers.{i}.mlp.fc1.weight` | [2048, 512] |
| `encoder_transformer.layers.{i}.mlp.fc2.weight` | [512, 2048] |
| `encoder_transformer.layers.{i}.self_attn_layer_scale.scale` | [512] |
| `encoder_transformer.layers.{i}.mlp_layer_scale.scale` | [512] |

## Downsample (between transformer and quantizer)

| Tensor | Shape |
|--------|-------|
| `downsample.conv.weight` | [512, 512, 4] |

No bias. Stride = kernel_size / 2 = 2.

## Quantizer (Split RVQ)

### Semantic (1 codebook)

| Tensor | Shape |
|--------|-------|
| `quantizer.semantic_residual_vector_quantizer.input_proj.weight` | [256, 512, 1] |
| `quantizer.semantic_residual_vector_quantizer.output_proj.weight` | [512, 256, 1] |
| `quantizer.semantic_residual_vector_quantizer.layers.0.codebook.embed_sum` | [2048, 256] |
| `quantizer.semantic_residual_vector_quantizer.layers.0.codebook.cluster_usage` | [2048] |
| `quantizer.semantic_residual_vector_quantizer.layers.0.codebook.initialized` | [1] |

### Acoustic (31 codebooks)

For each layer `j` in 0..31:

| Tensor | Shape |
|--------|-------|
| `quantizer.acoustic_residual_vector_quantizer.input_proj.weight` | [256, 512, 1] |
| `quantizer.acoustic_residual_vector_quantizer.output_proj.weight` | [512, 256, 1] |
| `quantizer.acoustic_residual_vector_quantizer.layers.{j}.codebook.embed_sum` | [2048, 256] |
| `quantizer.acoustic_residual_vector_quantizer.layers.{j}.codebook.cluster_usage` | [2048] |
| `quantizer.acoustic_residual_vector_quantizer.layers.{j}.codebook.initialized` | [1] |

Projection weights are 3D (1x1 conv format) — squeeze dim 2 to get 2D matrix.
Codebook embedding = embed_sum / max(cluster_usage, 1.0).

## Upsample

| Tensor | Shape |
|--------|-------|
| `upsample.conv.weight` | [512, 1, 4] |

## Decoder (mirror of encoder — not used for STT)

Decoder tensors follow the same pattern with `decoder.layers.{i}` and `decoder_transformer.layers.{i}`.

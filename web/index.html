<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STT — Browser Speech-to-Text</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
            color: #111;
            background: #fafafa;
        }
        h1 {
            margin-bottom: 0.5rem;
            font-size: 2rem;
            font-weight: 600;
        }
        .subtitle {
            margin-bottom: 2rem;
            color: #666;
            font-size: 0.95rem;
        }
        .card {
            background: #fff;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
        }
        .card h2 {
            font-size: 0.85rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            color: #888;
            margin-bottom: 1rem;
        }
        .status {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 1rem;
            font-size: 0.9rem;
        }
        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #999;
        }
        .status-dot.loading { background: #f0ad4e; }
        .status-dot.ready { background: #5cb85c; }
        .status-dot.error { background: #d9534f; }
        .status-dot.recording {
            background: #d9534f;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        .progress {
            height: 4px;
            background: #eee;
            border-radius: 2px;
            overflow: hidden;
            margin-bottom: 1rem;
            display: none;
        }
        .progress.visible {
            display: block;
        }
        .progress-bar {
            height: 100%;
            background: #007aff;
            width: 0%;
            transition: width 0.3s;
        }
        .controls {
            display: flex;
            gap: 0.5rem;
        }
        button {
            font-family: inherit;
            font-size: 0.95rem;
            padding: 0.6rem 1.2rem;
            cursor: pointer;
            border: 1px solid #ccc;
            background: #fff;
            border-radius: 6px;
            transition: all 0.15s;
        }
        button:hover:not(:disabled) {
            background: #f5f5f5;
            border-color: #999;
        }
        button:disabled {
            opacity: 0.4;
            cursor: not-allowed;
        }
        button.primary {
            background: #007aff;
            color: #fff;
            border-color: #007aff;
        }
        button.primary:hover:not(:disabled) {
            background: #0051d5;
            border-color: #0051d5;
        }
        button.recording {
            background: #d9534f;
            color: #fff;
            border-color: #d9534f;
            animation: pulse 1s infinite;
        }
        #transcript {
            margin-top: 0;
            padding: 1rem;
            min-height: 200px;
            border: 1px solid #eee;
            border-radius: 6px;
            background: #f9f9f9;
            white-space: pre-wrap;
            line-height: 1.6;
            font-size: 0.95rem;
            color: #111;
        }
        #transcript.empty {
            color: #999;
            font-style: italic;
        }
        button.test-file {
            font-size: 0.8rem;
            padding: 0.4rem 0.8rem;
            background: #f0f0f0;
        }
        .info {
            font-size: 0.85rem;
            color: #888;
            margin-top: 0.5rem;
        }
        #rtfInfo {
            font-size: 0.8rem;
            color: #888;
            margin-top: 0.5rem;
            font-family: 'SF Mono', Monaco, Consolas, monospace;
            display: none;
        }
        #metricsCard {
            display: none;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 0.75rem;
        }
        .metric {
            text-align: center;
        }
        .metric-value {
            font-size: 1.1rem;
            font-weight: 600;
            color: #007aff;
        }
        .metric-label {
            font-size: 0.7rem;
            color: #999;
            text-transform: uppercase;
            letter-spacing: 0.04em;
            margin-top: 0.15rem;
        }
        .streaming-cursor {
            display: inline-block;
            width: 2px;
            height: 1em;
            background: #007aff;
            margin-left: 2px;
            vertical-align: text-bottom;
            animation: blink 0.7s infinite;
        }
        @keyframes blink {
            0%, 100% { opacity: 1; }
            50% { opacity: 0; }
        }
    </style>
</head>
<body>
    <h1>Speech-to-Text</h1>
    <p class="subtitle">Client-side speech-to-text (English + French) — runs entirely in your browser via WebGPU.</p>

    <div class="card">
        <h2>Status</h2>
        <div class="status">
            <div class="status-dot" id="statusDot"></div>
            <span id="statusText">Checking browser support...</span>
        </div>
        <div class="progress" id="progressBar">
            <div class="progress-bar" id="progressFill"></div>
        </div>
        <p class="info" id="progressInfo"></p>
    </div>

    <div class="card">
        <h2>Controls</h2>
        <div class="controls">
            <button id="recordBtn" class="primary" disabled>Start Recording</button>
            <button id="fileBtn" disabled>Load WAV File</button>
            <button id="resetBtn" disabled>Reset</button>
            <input type="file" id="fileInput" accept=".wav,audio/wav" style="display:none">
        </div>
        <div class="controls" style="margin-top:0.5rem">
            <button class="test-file" data-src="test-bria.wav" disabled>bria (EN, 30s)</button>
            <button class="test-file" data-src="test-crepes-fr.wav" disabled>crepes (FR, 30s)</button>
            <button class="test-file" data-src="test-loona.wav" disabled>loona (1s)</button>
        </div>
        <p class="info">Click Start Recording or load a test file. Audio stays on this device.</p>
    </div>

    <div class="card">
        <h2>Transcript</h2>
        <div id="transcript" class="empty"><span id="transcriptText">Transcript will appear here as you speak...</span><span id="streamingCursor" class="streaming-cursor" style="display:none"></span></div>
        <div id="rtfInfo"></div>
    </div>

    <div class="card" id="metricsCard">
        <h2>Performance</h2>
        <div class="metrics-grid">
            <div class="metric">
                <div class="metric-value" id="metricTtfb">—</div>
                <div class="metric-label">TTFB (ms)</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="metricFps">—</div>
                <div class="metric-label">Frames/sec</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="metricRtf">—</div>
                <div class="metric-label">RTF</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="metricFrameMs">—</div>
                <div class="metric-label">ms/frame</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="metricMimiMs">—</div>
                <div class="metric-label">Mimi (ms)</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="metricSttMs">—</div>
                <div class="metric-label">STT (ms)</div>
            </div>
        </div>
    </div>

    <script type="module">
        const { SttClient } = await import('./stt-client.js');

        // UI elements
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const progressBar = document.getElementById('progressBar');
        const progressFill = document.getElementById('progressFill');
        const progressInfo = document.getElementById('progressInfo');
        const transcriptEl = document.getElementById('transcript');
        const transcriptTextEl = document.getElementById('transcriptText');
        const rtfInfoEl = document.getElementById('rtfInfo');
        const recordBtn = document.getElementById('recordBtn');
        const fileBtn = document.getElementById('fileBtn');
        const fileInput = document.getElementById('fileInput');
        const testFileBtns = document.querySelectorAll('.test-file');
        const resetBtn = document.getElementById('resetBtn');
        const metricsCard = document.getElementById('metricsCard');
        const metricTtfb = document.getElementById('metricTtfb');
        const metricFps = document.getElementById('metricFps');
        const metricRtf = document.getElementById('metricRtf');
        const metricFrameMs = document.getElementById('metricFrameMs');
        const metricMimiMs = document.getElementById('metricMimiMs');
        const metricSttMs = document.getElementById('metricSttMs');

        function updateMetrics(data) {
            metricsCard.style.display = 'block';
            if (data.ttfb != null && data.ttfb >= 0) {
                metricTtfb.textContent = data.ttfb.toFixed(0);
            }
            if (data.framesPerSec != null) {
                metricFps.textContent = data.framesPerSec.toFixed(1);
            }
            if (data.rtf != null) {
                metricRtf.textContent = (typeof data.rtf === 'object' ? data.rtf.total : data.rtf).toFixed(2);
            }
            if (data.avgFrameMs != null) {
                metricFrameMs.textContent = data.avgFrameMs.toFixed(1);
            }
            if (data.mimiMs != null) {
                metricMimiMs.textContent = data.mimiMs.toFixed(1);
            }
            if (data.sttMs != null) {
                metricSttMs.textContent = data.sttMs.toFixed(1);
            }
        }

        // State
        let client = null;
        let isRecording = false;
        let isProcessingFile = false;
        let transcriptText = '';

        function updateStatus(state, text) {
            statusDot.className = 'status-dot ' + state;
            statusText.textContent = text;
        }

        function formatBytes(bytes) {
            const mb = bytes / (1024 * 1024);
            return mb >= 1 ? `${mb.toFixed(1)} MB` : `${(bytes / 1024).toFixed(0)} KB`;
        }

        // Check WebGPU support
        if (!navigator.gpu) {
            updateStatus('error', 'WebGPU not supported. Use Chrome or Edge.');
            statusText.textContent = 'WebGPU not supported in this browser. Please use Chrome or Edge (version 113+).';
        } else {
            // Initialize client
            // For embedding on another domain, configure baseUrl and optional overrides:
            //   baseUrl: 'https://cdn.example.com/stt',
            //   shardList: ['shard-00000.gguf', 'shard-00001.gguf', ...],
            //   mimiUrl: 'https://cdn.example.com/stt/models/mimi.safetensors',
            //   tokenizerUrl: 'https://cdn.example.com/stt/models/tokenizer.model',
            client = new SttClient({
                onStatus: (text, ready, progress) => {
                    // Ignore stale processing status messages after stop
                    if (!isRecording && !isProcessingFile && text.startsWith('Processing')) {
                        return;
                    }
                    if (ready) {
                        updateStatus('ready', text);
                        recordBtn.disabled = false;
                        fileBtn.disabled = false;
                        testFileBtns.forEach(b => b.disabled = false);
                        resetBtn.disabled = false;
                        isProcessingFile = false;
                        progressBar.classList.remove('visible');
                        progressInfo.textContent = '';
                    } else if (isProcessingFile && text.startsWith('Processing')) {
                        updateStatus('loading', text);
                    } else {
                        updateStatus('loading', text);

                        if (progress) {
                            progressBar.classList.add('visible');
                            const percent = progress.total > 0
                                ? (progress.loaded / progress.total) * 100
                                : 0;
                            progressFill.style.width = percent + '%';
                            progressInfo.textContent = `${formatBytes(progress.loaded)} / ${formatBytes(progress.total)}`;
                        }
                    }
                },

                onTranscript: (text, isFinal, rtf) => {
                    const cursor = document.getElementById('streamingCursor');
                    if (text) {
                        transcriptText += text;
                        transcriptTextEl.textContent = transcriptText;
                        transcriptEl.classList.remove('empty');
                    }

                    if (isFinal) {
                        if (transcriptText) transcriptText += ' ';
                        if (cursor) cursor.style.display = 'none';

                        if (rtf) {
                            const procTime = (rtf.audioDuration * rtf.total).toFixed(1);
                            const speedup = (1 / rtf.total).toFixed(1);
                            const faster = rtf.total < 1.0 ? ` — ${speedup}x faster than real-time` : '';
                            rtfInfoEl.textContent = `${rtf.audioDuration.toFixed(1)}s audio processed in ${procTime}s (RTF: ${rtf.total.toFixed(2)}x)${faster}`;
                            rtfInfoEl.style.display = 'block';
                        }
                    } else {
                        if (cursor) cursor.style.display = 'inline-block';
                    }
                },

                onMetrics: (data) => {
                    updateMetrics(data);
                },

                onError: (err) => {
                    updateStatus('error', 'Error: ' + err.message);
                    console.error(err);
                }
            });

            // Initialize and load model
            (async () => {
                try {
                    await client.init();
                } catch (err) {
                    updateStatus('error', 'Failed to initialize: ' + err.message);
                    console.error(err);
                }
            })();
        }

        // Record button
        recordBtn.addEventListener('click', async () => {
            if (!isRecording) {
                // Start recording
                try {
                    await client.startRecording();
                    isRecording = true;
                    recordBtn.textContent = 'Stop Recording';
                    recordBtn.classList.add('recording');
                    recordBtn.classList.remove('primary');
                    statusDot.classList.add('recording');
                    updateStatus('recording', 'Recording...');
                } catch (err) {
                    updateStatus('error', 'Microphone error: ' + err.message);
                    console.error(err);
                }
            } else {
                // Stop recording
                client.stopRecording();
                isRecording = false;
                recordBtn.textContent = 'Start Recording';
                recordBtn.classList.remove('recording');
                recordBtn.classList.add('primary');
                statusDot.classList.remove('recording');
                updateStatus('ready', 'Ready');
            }
        });

        // Shared: decode audio and feed to worker
        async function feedAudioFile(arrayBuf, label) {
            updateStatus('loading', `Decoding ${label}...`);
            fileBtn.disabled = true;
            recordBtn.disabled = true;
            testFileBtns.forEach(b => b.disabled = true);
            isProcessingFile = true;

            try {
                // Decode to 24kHz mono (Mimi's native rate)
                const offlineCtx = new OfflineAudioContext(1, 1, 24000);
                const audioBuf = await offlineCtx.decodeAudioData(arrayBuf);

                // Resample to 24kHz mono
                const duration = audioBuf.duration;
                const outLen = Math.ceil(duration * 24000);
                const resampleCtx = new OfflineAudioContext(1, outLen, 24000);
                const source = resampleCtx.createBufferSource();
                source.buffer = audioBuf;
                source.connect(resampleCtx.destination);
                source.start(0);
                const rendered = await resampleCtx.startRendering();
                const pcm = rendered.getChannelData(0);

                // Reset state before feeding
                client.worker.postMessage({ type: 'reset' });
                transcriptText = '';
                transcriptTextEl.textContent = '';
                transcriptEl.classList.remove('empty');

                // Feed in ~100ms chunks (2400 samples)
                const CHUNK = 2400;
                updateStatus('loading', `Processing ${(pcm.length/24000).toFixed(1)}s of audio...`);
                for (let i = 0; i < pcm.length; i += CHUNK) {
                    const chunk = pcm.slice(i, Math.min(i + CHUNK, pcm.length));
                    client.worker.postMessage(
                        { type: 'audio', samples: chunk },
                        [chunk.buffer]
                    );
                    // Yield to let worker process and UI update
                    if (i % (CHUNK * 10) === 0) {
                        await new Promise(r => setTimeout(r, 0));
                    }
                }

                // Flush remaining tokens — "Done" status comes from worker via onStatus('Ready')
                client.worker.postMessage({ type: 'stop' });
            } catch (err) {
                updateStatus('error', 'File error: ' + err.message);
                console.error(err);
                isProcessingFile = false;
                fileBtn.disabled = false;
                recordBtn.disabled = false;
                testFileBtns.forEach(b => b.disabled = false);
            }
        }

        // File picker button
        fileBtn.addEventListener('click', () => fileInput.click());
        fileInput.addEventListener('change', async (e) => {
            const file = e.target.files[0];
            if (!file) return;
            fileInput.value = '';
            await feedAudioFile(await file.arrayBuffer(), file.name);
        });

        // Test file buttons — fetch from server and feed
        testFileBtns.forEach(btn => {
            btn.addEventListener('click', async () => {
                const src = btn.dataset.src;
                const resp = await fetch(src);
                if (!resp.ok) {
                    updateStatus('error', `Failed to fetch ${src}`);
                    return;
                }
                await feedAudioFile(await resp.arrayBuffer(), src);
            });
        });

        // Reset button
        resetBtn.addEventListener('click', () => {
            transcriptText = '';
            transcriptTextEl.textContent = 'Transcript will appear here as you speak...';
            transcriptEl.classList.add('empty');
            document.getElementById('streamingCursor').style.display = 'none';
            rtfInfoEl.style.display = 'none';
            rtfInfoEl.textContent = '';
            metricsCard.style.display = 'none';
            metricTtfb.textContent = '—';
            metricFps.textContent = '—';
            metricRtf.textContent = '—';
            metricFrameMs.textContent = '—';
            metricMimiMs.textContent = '—';
            metricSttMs.textContent = '—';
            client.reset();
            updateStatus('ready', 'Ready');
        });
    </script>
</body>
</html>
